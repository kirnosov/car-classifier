{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing VGG16 network\n",
    "\n",
    "In this notebook I use the data explored and processed in notebooks 1-3 to see how well the pretrained VGG16 model works as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "#TODO implement this function\n",
    "#from cars_utils import plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC  IMAGE, AND BATCH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions:\n",
    "IMG_WIDTH, IMG_HEIGHT = 100*2, 75*2\n",
    "\n",
    "BASE = os.getcwd()\n",
    "SAVE_DIR = os.path.join(BASE, 'data', 'VGG16Av2')\n",
    "BASE = os.path.join(BASE, 'data', 'cars_dataset', 'keras')\n",
    "\n",
    "### Settings for full training\n",
    "# TRAIN_DATA_DIR = os.path.join(BASE, 'train')\n",
    "# VALIDATION_DATA_DIR = os.path.join(BASE, 'validation')\n",
    "# NB_CLASSES = 196\n",
    "# NB_TRAIN_SAMPLES = 11329\n",
    "# NB_VALIDATION_SAMPLES = 2428\n",
    "# BATCH_SIZE = 64\n",
    "\n",
    "### Settings for fast checking\n",
    "TRAIN_DATA_DIR = os.path.join(BASE, 'fast', 'train')\n",
    "VALIDATION_DATA_DIR = os.path.join(BASE, 'fast', 'validation')\n",
    "NB_CLASSES = 196\n",
    "NB_TRAIN_SAMPLES = NB_CLASSES*2\n",
    "NB_VALIDATION_SAMPLES = NB_CLASSES\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    INPUT_SHAPE = (3, IMG_WIDTH, IMG_HEIGHT)\n",
    "else:\n",
    "    INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 32\n",
      "This is the number of trainable weights after freezing the conv base: 6\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512*4, activation='relu'))\n",
    "model.add(Dense(512*4, activation='relu'))\n",
    "model.add(Dense(NB_CLASSES, activation='softmax'))\n",
    "\n",
    "conv_base.trainable = True\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 392 images belonging to 196 classes.\n",
      "Found 196 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom metrics to measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_acc(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[metrics.categorical_accuracy, top_3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "98/98 [==============================] - 624s 6s/step - loss: 15.9624 - categorical_accuracy: 0.0026 - top_3_acc: 0.9796 - val_loss: 16.0359 - val_categorical_accuracy: 0.0051 - val_top_3_acc: 1.0000\n",
      "\n",
      "traing took: 10.416666666666666 minutes\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "start_time = time.time()\n",
    "VGG16_0_1_summary = model.fit_generator(train_generator,\n",
    "                                   steps_per_epoch=NB_TRAIN_SAMPLES // BATCH_SIZE,\n",
    "                                   epochs=EPOCHS,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   validation_steps=NB_VALIDATION_SAMPLES // BATCH_SIZE)\n",
    "end_time = time.time()\n",
    "\n",
    "print('\\ntraing took: {} minutes' .format(round(end_time - start_time, 0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
