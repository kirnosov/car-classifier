{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing InceptionV3 network (variation 14) Fine-tuning\n",
    "\n",
    "Based on variant 13:\n",
    "\n",
    "`optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, schedule_decay=0.004)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "#TODO implement this function\n",
    "from cars_utils import time_save_model, plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC  IMAGE, AND BATCH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions:\n",
    "IMG_WIDTH, IMG_HEIGHT = 299, 299\n",
    "\n",
    "WORKING_DIR = os.getcwd()\n",
    "BASE = os.path.join(WORKING_DIR, 'data', 'cars_dataset', 'keras')\n",
    "\n",
    "SAVE_DIR = os.path.join(WORKING_DIR, 'data', 'InceptionV3')\n",
    "\n",
    "### Settings for full training\n",
    "TRAIN_DATA_DIR = os.path.join(BASE, 'train')\n",
    "VALIDATION_DATA_DIR = os.path.join(BASE, 'validation')\n",
    "NB_CLASSES = 196\n",
    "NB_TRAIN_SAMPLES = 11329\n",
    "NB_VALIDATION_SAMPLES = 2428\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "### Settings for fast checking\n",
    "# SAVE_DIR = os.path.join(WORKING_DIR, 'data', 'fast_test')\n",
    "# TRAIN_DATA_DIR = os.path.join(BASE, 'fast', 'train')\n",
    "# VALIDATION_DATA_DIR = os.path.join(BASE, 'fast', 'validation')\n",
    "# NB_CLASSES = 196\n",
    "# NB_TRAIN_SAMPLES = NB_CLASSES*2\n",
    "# NB_VALIDATION_SAMPLES = NB_CLASSES\n",
    "# BATCH_SIZE = 4\n",
    "\n",
    "### Settings for faster checking\n",
    "# SAVE_DIR = os.path.join(WORKING_DIR, 'data', 'fast_v2_test')\n",
    "# TRAIN_DATA_DIR = os.path.join(BASE, 'fast_v2', 'train')\n",
    "# VALIDATION_DATA_DIR = os.path.join(BASE, 'fast_v2', 'validation')\n",
    "# NB_CLASSES = 6\n",
    "# NB_TRAIN_SAMPLES = NB_CLASSES*2\n",
    "# NB_VALIDATION_SAMPLES = NB_CLASSES\n",
    "# BATCH_SIZE = 4\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    INPUT_SHAPE = (3, IMG_WIDTH, IMG_HEIGHT)\n",
    "else:\n",
    "    INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "conv_base = InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    input_shape=INPUT_SHAPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_layer_config = {\n",
    "    'activation': 'softmax',\n",
    "    'activity_regularizer': None,\n",
    "    'bias_constraint': None,\n",
    "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
    "    'bias_regularizer': None,\n",
    "    'kernel_constraint': None,\n",
    "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
    "                           'config': {\n",
    "                               'distribution': 'uniform',\n",
    "                               'mode': 'fan_avg',\n",
    "                               'scale': 1.0,\n",
    "                               'seed': 8}\n",
    "                          },\n",
    "    'kernel_regularizer': None,\n",
    "    'name': 'predictions',\n",
    "    'trainable': True,\n",
    "    'units': NB_CLASSES,\n",
    "    'use_bias': True}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Dense(**pred_layer_config))\n",
    "\n",
    "WEIGHT_PATH = os.path.join(SAVE_DIR, 'InceptionV3_13_10_20.h5')\n",
    "model.load_weights(WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 190\n",
      "This is the number of trainable weights before freezing the conv base: 2\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = True\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))\n",
    "\n",
    "conv_base.trainable = False\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after after limited freezing the conv base: 14\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name in [\n",
    "        'conv2d_86', 'batch_normalization_86',\n",
    "        'conv2d_88', 'batch_normalization_88',\n",
    "        'conv2d_89', 'batch_normalization_89',\n",
    "        'conv2d_92', 'batch_normalization_92',\n",
    "        'conv2d_93', 'batch_normalization_93',\n",
    "        'conv2d_94', 'batch_normalization_94'\n",
    "    ]:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "print('This is the number of trainable weights after '\n",
    "      'after limited freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 196)               401604    \n",
      "=================================================================\n",
      "Total params: 22,204,388\n",
      "Trainable params: 3,221,700\n",
      "Non-trainable params: 18,982,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11329 images belonging to 196 classes.\n",
      "Found 2428 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=7)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom metrics to measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_acc(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_5_acc(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "optimizer = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, schedule_decay=0.004)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=[metrics.categorical_accuracy, top_3_acc, top_5_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "354/354 [==============================] - 290s 820ms/step - loss: 3.3408 - categorical_accuracy: 0.2775 - top_3_acc: 0.4616 - top_5_acc: 0.5568 - val_loss: 3.2226 - val_categorical_accuracy: 0.3104 - val_top_3_acc: 0.5100 - val_top_5_acc: 0.6138\n",
      "Epoch 2/10\n",
      "354/354 [==============================] - 287s 810ms/step - loss: 2.2738 - categorical_accuracy: 0.4320 - top_3_acc: 0.6427 - top_5_acc: 0.7325 - val_loss: 2.7238 - val_categorical_accuracy: 0.3729 - val_top_3_acc: 0.5817 - val_top_5_acc: 0.6787\n",
      "Epoch 3/10\n",
      "354/354 [==============================] - 288s 814ms/step - loss: 1.9150 - categorical_accuracy: 0.5051 - top_3_acc: 0.7212 - top_5_acc: 0.7972 - val_loss: 2.4678 - val_categorical_accuracy: 0.4054 - val_top_3_acc: 0.6196 - val_top_5_acc: 0.7100\n",
      "Epoch 4/10\n",
      "354/354 [==============================] - 287s 809ms/step - loss: 1.6914 - categorical_accuracy: 0.5524 - top_3_acc: 0.7605 - top_5_acc: 0.8324 - val_loss: 2.3441 - val_categorical_accuracy: 0.4321 - val_top_3_acc: 0.6496 - val_top_5_acc: 0.7300\n",
      "Epoch 5/10\n",
      "354/354 [==============================] - 287s 812ms/step - loss: 1.5218 - categorical_accuracy: 0.5849 - top_3_acc: 0.7925 - top_5_acc: 0.8592 - val_loss: 2.2736 - val_categorical_accuracy: 0.4317 - val_top_3_acc: 0.6538 - val_top_5_acc: 0.7479\n",
      "Epoch 6/10\n",
      "354/354 [==============================] - 285s 806ms/step - loss: 1.4162 - categorical_accuracy: 0.6134 - top_3_acc: 0.8150 - top_5_acc: 0.8762 - val_loss: 2.2177 - val_categorical_accuracy: 0.4542 - val_top_3_acc: 0.6663 - val_top_5_acc: 0.7562\n",
      "Epoch 7/10\n",
      "354/354 [==============================] - 285s 804ms/step - loss: 1.3069 - categorical_accuracy: 0.6381 - top_3_acc: 0.8396 - top_5_acc: 0.8970 - val_loss: 2.1383 - val_categorical_accuracy: 0.4612 - val_top_3_acc: 0.6737 - val_top_5_acc: 0.7575\n",
      "Epoch 8/10\n",
      "354/354 [==============================] - 285s 806ms/step - loss: 1.2266 - categorical_accuracy: 0.6660 - top_3_acc: 0.8491 - top_5_acc: 0.8994 - val_loss: 2.2167 - val_categorical_accuracy: 0.4567 - val_top_3_acc: 0.6733 - val_top_5_acc: 0.7604\n",
      "Epoch 9/10\n",
      "354/354 [==============================] - 287s 810ms/step - loss: 1.1649 - categorical_accuracy: 0.6840 - top_3_acc: 0.8606 - top_5_acc: 0.9123 - val_loss: 2.1623 - val_categorical_accuracy: 0.4692 - val_top_3_acc: 0.6833 - val_top_5_acc: 0.7675\n",
      "Epoch 10/10\n",
      "354/354 [==============================] - 285s 804ms/step - loss: 1.1219 - categorical_accuracy: 0.6836 - top_3_acc: 0.8634 - top_5_acc: 0.9167 - val_loss: 1.9174 - val_categorical_accuracy: 0.5171 - val_top_3_acc: 0.7238 - val_top_5_acc: 0.8013\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "start_time = time.time()\n",
    "summary = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=NB_TRAIN_SAMPLES // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=NB_VALIDATION_SAMPLES // BATCH_SIZE)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing took: 48.0 minutes\n"
     ]
    }
   ],
   "source": [
    "time_save_model(model,\n",
    "                summary.history,\n",
    "                start_time, end_time,\n",
    "                'InceptionV3_14_0_10',\n",
    "                SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_list = ['categorical_accuracy',\n",
    "            'top_3_acc',\n",
    "            'top_5_acc',\n",
    "            'loss']\n",
    "show = plot_metrics(summary.history, key_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
